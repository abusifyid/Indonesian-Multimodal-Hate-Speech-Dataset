{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8080467,
          "sourceType": "datasetVersion",
          "datasetId": 4769209
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "k4zzioorrOkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "OmPfoK9ptT7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images(image_folder, image_names, target_size=(224, 224)):\n",
        "    features = []\n",
        "    for image_name in image_names:\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, target_size)\n",
        "            image = image / 255.0\n",
        "            image_array = image.flatten()\n",
        "            features.append(image_array)\n",
        "    return np.array(features)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('path_to_dataset/multimodal_tweets_dataset.csv')\n",
        "df['anotasi'] = df['anotasi'].map({'not hate': 0, 'hate': 1})\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(df, df['anotasi']):\n",
        "    df_train = df.iloc[train_index]\n",
        "    df_test = df.iloc[test_index]\n",
        "\n",
        "train_images = df_train['images'].tolist()\n",
        "train_texts = df_train['tweet_text'].tolist()\n",
        "train_labels = df_train['anotasi'].tolist()\n",
        "test_images = df_test['images'].tolist()\n",
        "test_texts = df_test['tweet_text'].tolist()\n",
        "test_labels = df_test['anotasi'].tolist()\n",
        "\n",
        "train_image_features = load_and_preprocess_images(\"/content/drive/MyDrive/Multimodal Research/selected_images/\", train_images)\n",
        "test_image_features = load_and_preprocess_images(\"/content/drive/MyDrive/Multimodal Research/selected_images/\", test_images)\n",
        "\n",
        "cv = CountVectorizer()\n",
        "train_text_features = cv.fit_transform(train_texts).toarray()\n",
        "test_text_features = cv.transform(test_texts).toarray()\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "train_text_features_resampled, train_labels_resampled = ros.fit_resample(train_text_features, train_labels)\n",
        "train_image_features_resampled, train_labels_resampled = ros.fit_resample(train_image_features, train_labels)"
      ],
      "metadata": {
        "id": "bXMq8bEbrSWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_combined_features = np.concatenate((train_text_features_resampled, train_image_features_resampled), axis=1)\n",
        "test_combined_features = np.concatenate((test_text_features, test_image_features), axis=1)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(train_combined_features, train_labels_resampled)\n",
        "\n",
        "predictions = model.predict(test_combined_features)\n",
        "\n",
        "def calculate_and_print_metrics(true_labels, predictions, model_name):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "calculate_and_print_metrics(test_labels, predictions, \"Early Fusion Naive Bayes\")"
      ],
      "metadata": {
        "id": "_MN2xCLZtyyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_combined_features = np.concatenate((train_text_features_resampled, train_image_features_resampled), axis=1)\n",
        "test_combined_features = np.concatenate((test_text_features, test_image_features), axis=1)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(train_combined_features, train_labels_resampled)\n",
        "\n",
        "predictions = model.predict(test_combined_features)\n",
        "\n",
        "def calculate_and_print_metrics(true_labels, predictions, model_name):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "calculate_and_print_metrics(test_labels, predictions, \"Early Fusion Random Forest\")"
      ],
      "metadata": {
        "id": "ZfaffYIXwSia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_combined_features = np.concatenate((train_text_features_resampled, train_image_features_resampled), axis=1)\n",
        "test_combined_features = np.concatenate((test_text_features, test_image_features), axis=1)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(train_combined_features, train_labels_resampled)\n",
        "\n",
        "predictions = model.predict(test_combined_features)\n",
        "\n",
        "def calculate_and_print_metrics(true_labels, predictions, model_name):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "calculate_and_print_metrics(test_labels, predictions, \"Early Fusion Decision Tree\")"
      ],
      "metadata": {
        "id": "BpqONrz5wbR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_combined_features = np.concatenate((train_text_features_resampled, train_image_features_resampled), axis=1)\n",
        "test_combined_features = np.concatenate((test_text_features, test_image_features), axis=1)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(train_combined_features, train_labels_resampled)\n",
        "\n",
        "predictions = model.predict(test_combined_features)\n",
        "\n",
        "def calculate_and_print_metrics(true_labels, predictions, model_name):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "calculate_and_print_metrics(test_labels, predictions, \"Early Fusion Logistic Regression\")"
      ],
      "metadata": {
        "id": "KMhswg5xwkJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_combined_features = np.concatenate((train_text_features_resampled, train_image_features_resampled), axis=1)\n",
        "test_combined_features = np.concatenate((test_text_features, test_image_features), axis=1)\n",
        "\n",
        "nb_model = AdaBoostClassifier()\n",
        "nb_model.fit(train_combined_features, train_labels_resampled)\n",
        "\n",
        "predictions = nb_model.predict(test_combined_features)\n",
        "\n",
        "def calculate_and_print_metrics(true_labels, predictions, model_name):\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='macro')\n",
        "    recall = recall_score(true_labels, predictions, average='macro')\n",
        "    f1 = f1_score(true_labels, predictions, average='macro')\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "calculate_and_print_metrics(test_labels, predictions, \"Early Fusion AdaBoost\")"
      ],
      "metadata": {
        "id": "LwdC_tAgwvcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning (RNN+CNN)"
      ],
      "metadata": {
        "id": "PbGZH_CfFai3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, GlobalAveragePooling2D, LSTM, SpatialDropout1D, Embedding, concatenate, GRU, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet50, EfficientNetV2S, Xception\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dense, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "nhLjPatnoPaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('path_to_dataset/multimodal_tweets_dataset.csv')\n",
        "df['anotasi'] = df['anotasi'].map({'not hate': 0, 'hate': 1})\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in sss.split(df, df['anotasi']):\n",
        "    df_train = df.iloc[train_index]\n",
        "    df_test = df.iloc[test_index]\n",
        "\n",
        "train_texts, train_labels, train_images = df_train['tweet_text'].tolist(), df_train['anotasi'].tolist(), df_train['images'].tolist()\n",
        "test_texts, test_labels, test_images = df_test['tweet_text'].tolist(), df_test['anotasi'].tolist(), df_test['images'].tolist()\n",
        "\n",
        "def load_and_preprocess_images(image_folder, image_names, target_size):\n",
        "    images = []\n",
        "    for image_name in image_names:\n",
        "        image_path = os.path.join(image_folder, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, target_size)\n",
        "            image = image / 255.0\n",
        "            print(image.shape)\n",
        "            images.append(image)\n",
        "    return np.array(images)\n",
        "\n",
        "train_images = load_and_preprocess_images(\"/content/drive/MyDrive/Multimodal Research/selected_images/\", train_images, (224, 224))\n",
        "test_images = load_and_preprocess_images(\"/content/drive/MyDrive/Multimodal Research/selected_images/\", test_images, (224, 224))\n",
        "\n",
        "max_features = 10000\n",
        "max_length = 100\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
        "test_texts = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "train_texts = pad_sequences(train_texts, maxlen=max_length)\n",
        "test_texts = pad_sequences(test_texts, maxlen=max_length)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "train_texts_resampled, train_labels_resampled = ros.fit_resample(train_texts, train_labels_encoded)\n",
        "\n",
        "train_images_reshaped = train_images.reshape((train_images.shape[0], -1))\n",
        "train_images_resampled, train_labels_image_resampled = ros.fit_resample(train_images_reshaped, train_labels_encoded)\n",
        "train_images_resampled = train_images_resampled.reshape((-1, 224, 224, 3))\n",
        "\n",
        "train_labels_resampled = to_categorical(train_labels_resampled, num_classes=2)\n",
        "test_labels = to_categorical(test_labels, num_classes=2)"
      ],
      "metadata": {
        "id": "kvluFLs3oQCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "lstm_output = LSTM(20, dropout=0.2, recurrent_dropout=0.2)(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, lstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "4O8wXiwSZO9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "bilstm_output = Bidirectional(LSTM(20, dropout=0.2, recurrent_dropout=0.2))(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, bilstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "wY9B7_hDVUa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "lstm_output = LSTM(20, dropout=0.2, recurrent_dropout=0.2)(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, lstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "ckjMUHUQW2zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "bilstm_output = Bidirectional(LSTM(20, dropout=0.2, recurrent_dropout=0.2))(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, bilstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "-AcE6BZfXff3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "lstm_output = LSTM(20, dropout=0.2, recurrent_dropout=0.2)(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, lstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "2UHpNI6XX3Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image input\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "x = base_model.output\n",
        "image_cnn = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Text input\n",
        "text_input = Input(shape=(max_length,))\n",
        "embedded_text = Embedding(max_features, 100, input_length=max_length)(text_input)\n",
        "embedded_text = SpatialDropout1D(0.2)(embedded_text)\n",
        "bilstm_output = Bidirectional(LSTM(20, dropout=0.2, recurrent_dropout=0.2))(embedded_text)\n",
        "\n",
        "# Combine text and image features\n",
        "concatenated = concatenate([image_cnn, bilstm_output])\n",
        "output = Dense(2, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit([train_images_resampled, train_texts_resampled], train_labels_resampled, epochs=10, batch_size=64)\n",
        "\n",
        "y_pred = model.predict([test_images, test_texts])\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, y_pred)\n",
        "precision, recall, fscore, _ = precision_recall_fscore_support(true_labels, y_pred, average='macro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {fscore}\")"
      ],
      "metadata": {
        "id": "MXjLQ-EvXwvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}